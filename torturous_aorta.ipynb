{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'nlp_torturous_aorta.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from config import DATASTORE\n",
    "\n",
    "\n",
    "subset = pd.read_hdf(os.path.join(DATASTORE, 'store.h5'), '/subset')\n",
    "subset = subset.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review 100 reports randomly selected from sample10k"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "result = {}\n",
    "experience = dict()\n",
    "\n",
    "for i, (index, row) in enumerate(subset.sample(100).iterrows()):\n",
    "    if i < len(result):\n",
    "        continue\n",
    "    print('='*20, i + 1)\n",
    "    view = '\\n'.join(['>>FINDINGS:', \n",
    "                          str(row['FINDINGS']).replace('$', '\\n').strip(),\n",
    "                          '>>IMPRESSION:',\n",
    "                          str(row['IMPRESSIONS']).replace('$', '\\n').strip()])\n",
    "    if view in experience:\n",
    "        keyin = experience[view]\n",
    "    else:\n",
    "        print(view)\n",
    "        keyin = input('Positive or negative? [y/n]')\n",
    "        result[index] = keyin\n",
    "        experience[view] = keyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These pattern was design by observation the reports above\n",
    "pattern = r'(?i)(tortuo[^\\.]*?aort(a|ic)|aort(a|ic)[^\\.]*?tortuo\\w+|HCVD|H\\.C\\.V\\.D)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doctor_profile(dataset, pattern):\n",
    "    \"\"\"Given regex pattern, return the profile about how the doctor report this pattern\n",
    "    return the doctor/count/workload/ratio \n",
    "    \"\"\"\n",
    "    pos = dataset[dataset['FINDINGS'].str.contains(pattern)]\n",
    "    dr_who_report = pos['CONFIRMDR']\n",
    "    workload = Counter(subset['CONFIRMDR']).most_common()\n",
    "    profile = pd.DataFrame(workload, columns=['name', 'workload'] ).set_index('name', drop=True)\n",
    "    report_count = Counter(dr_who_report).most_common()\n",
    "    report_count = pd.DataFrame(report_count, columns=['name', 'count'] ).set_index('name', drop=True)\n",
    "    profile = profile.assign(count=report_count).fillna(0)\n",
    "    profile = profile.assign(ratio=profile['count']/profile['workload'])\n",
    "    return profile.sort_values('ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeroyang/.local/share/virtualenvs/qrabbit-nlp-2666-b4E/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workload</th>\n",
       "      <th>count</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>謝麗莎</th>\n",
       "      <td>90</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.755556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>曾水權</th>\n",
       "      <td>939</td>\n",
       "      <td>605.0</td>\n",
       "      <td>0.644302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>歐陽翊潔</th>\n",
       "      <td>171</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.543860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>王裕仁</th>\n",
       "      <td>97</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.443299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      workload  count     ratio\n",
       "name                           \n",
       "謝麗莎         90   68.0  0.755556\n",
       "曾水權        939  605.0  0.644302\n",
       "歐陽翊潔       171   93.0  0.543860\n",
       "王裕仁         97   43.0  0.443299"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.4\n",
    "profile = doctor_profile(subset, pattern)\n",
    "sensitive_doctors = profile[(profile['ratio'] > threshold) & (profile['workload'] > 50)]; sensitive_doctors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_doctors = sensitive_doctors.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeroyang/.local/share/virtualenvs/qrabbit-nlp-2666-b4E/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84835"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full = pd.read_hdf(os.path.join(DATASTORE, 'store.h5'), '/femh').fillna('')\n",
    "relaible_reports = full[full['CONFIRMDR'].isin(sensitive_doctors)]\n",
    "pos_full = full[full['FINDINGS'].str.contains(pattern)]\n",
    "len(pos_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reports = pos_full\n",
    "positive_reports = positive_reports.assign(label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正樣本:84835, 負樣本:21215\n"
     ]
    }
   ],
   "source": [
    "pos_neg = pd.merge(relaible_reports, positive_reports, how='outer', left_on='ACCNO', right_index=True)\n",
    "pos_neg['label'].fillna(0, inplace=True)\n",
    "stats = Counter(pos_neg['label'])\n",
    "print('正樣本:{}, 負樣本:{}'.format(stats[1.0], stats[0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg[['label']].to_csv(os.path.join('data', file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QC of Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_output = pd.read_csv(os.path.join('data', file_name), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('data/QC/pos', ignore_errors=True)\n",
    "shutil.rmtree('data/QC/neg', ignore_errors=True)\n",
    "os.makedirs('data/QC/pos')\n",
    "os.makedirs('data/QC/neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_file = pd.merge(subset, system_output, left_index=True, right_index=True)[['label']]\n",
    "\n",
    "for accno in has_file[has_file['label']==1].sample(50).index:\n",
    "    src = os.path.join(DATASTORE,'subset/{}.png'.format(accno))\n",
    "    dst = 'data/QC/pos/{}.png'.format(accno)\n",
    "    shutil.copy(src, dst)\n",
    "    \n",
    "for accno in has_file[has_file['label']==0].sample(50).index:\n",
    "    src = os.path.join(DATASTORE,'subset/{}.png'.format(accno))\n",
    "    dst = 'data/QC/neg/{}.png'.format(accno)\n",
    "    shutil.copy(src, dst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Varify results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
